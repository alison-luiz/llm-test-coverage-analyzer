# LLM Test Coverage Analyzer

<div align="center">

**Trabalho de ConclusÃ£o de Curso**

**Universidade Unicesumar - MaringÃ¡**

![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)
![Node.js](https://img.shields.io/badge/Node.js-43853D?style=for-the-badge&logo=node.js&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![Anthropic](https://img.shields.io/badge/Anthropic-191919?style=for-the-badge&logo=anthropic&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)

</div>

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Funcionalidades](#-funcionalidades)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Arquitetura](#-arquitetura)
- [LicenÃ§a](#-licenÃ§a)
- [Autor](#-autor)

---

## ğŸ¯ Sobre o Projeto

O **LLM Test Coverage Analyzer** Ã© um sistema inteligente que utiliza Large Language Models (LLMs) para anÃ¡lise automÃ¡tica de gaps de cobertura de testes em projetos de software. O sistema Ã© capaz de:

- Analisar relatÃ³rios de cobertura de testes
- Identificar lacunas na cobertura
- Integrar-se com repositÃ³rios GitHub
- Gerar anÃ¡lises detalhadas utilizando inteligÃªncia artificial
- Fornecer insights sobre a qualidade dos testes
- Suportar mÃºltiplos provedores LLM (OpenAI GPT-5 e Anthropic Claude)

### ğŸ¤– Suporte Multi-Provider

O sistema oferece flexibilidade na escolha do provedor LLM:

- **OpenAI (GPT-5)**: Modelos amplamente testados e documentados
- **Anthropic (Claude 4.5 Sonnet)**: Modelos de Ãºltima geraÃ§Ã£o com excelente capacidade de anÃ¡lise

Este projeto foi desenvolvido como Trabalho de ConclusÃ£o de Curso (TCC) do curso de graduaÃ§Ã£o da Unicesumar - Centro UniversitÃ¡rio de MaringÃ¡.

---

## âœ¨ Funcionalidades

- ğŸ” **AnÃ¡lise AutomÃ¡tica de Cobertura**: Processa relatÃ³rios de cobertura e identifica gaps
- ğŸ¤– **IntegraÃ§Ã£o com LLMs**: Utiliza modelos de linguagem avanÃ§ados para anÃ¡lise inteligente
- ğŸ“Š **GeraÃ§Ã£o de RelatÃ³rios**: Cria relatÃ³rios detalhados sobre a qualidade dos testes (JSON e TXT)
- ğŸ”— **IntegraÃ§Ã£o GitHub**: Conecta-se diretamente com repositÃ³rios para anÃ¡lise
- ğŸ“ **AnÃ¡lise Local**: Suporta anÃ¡lise de repositÃ³rios locais
- ğŸ’¾ **PersistÃªncia de Dados**: Armazena anÃ¡lises e relatÃ³rios para consulta posterior
- â±ï¸ **MÃ©tricas de Performance**: Rastreia e exibe tempos detalhados de execuÃ§Ã£o (clonagem, instalaÃ§Ã£o, testes, extraÃ§Ã£o de cÃ³digo, anÃ¡lise LLM)
- ğŸ“ **Sistema de Logs**: Captura e salva todos os logs de execuÃ§Ã£o em arquivos TXT para auditoria

---

## ğŸš€ Tecnologias Utilizadas

- **[TypeScript](https://www.typescriptlang.org/)**: Linguagem de programaÃ§Ã£o principal
- **[Node.js](https://nodejs.org/)**: Runtime JavaScript
- **[OpenAI API](https://openai.com/)**: IntegraÃ§Ã£o com modelos GPT (GPT-4, GPT-3.5)
- **[Anthropic API](https://www.anthropic.com/)**: IntegraÃ§Ã£o com modelos Claude
- **[Octokit](https://github.com/octokit/rest.js)**: Cliente GitHub API
- **[Axios](https://axios-http.com/)**: Cliente HTTP
- **[dotenv](https://github.com/motdotla/dotenv)**: Gerenciamento de variÃ¡veis de ambiente

---

## ğŸ“¦ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisarÃ¡ ter instalado em sua mÃ¡quina:

- [Node.js](https://nodejs.org/) (versÃ£o 18 ou superior)
- [npm](https://www.npmjs.com/) ou [yarn](https://yarnpkg.com/)
- Uma chave API de um dos provedores LLM:
  - **OpenAI**: [obtenha aqui](https://platform.openai.com/api-keys) (GPT-5)
  - **Anthropic**: [obtenha aqui](https://console.anthropic.com/) (Claude 4.5 Sonnet)
- (Opcional) Token de acesso do GitHub para anÃ¡lise de repositÃ³rios privados

---

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/alison-luiz/llm-test-coverage-analyzer.git
cd llm-test-coverage-analyzer
```

2. Instale as dependÃªncias:

```bash
npm install
```

3. Compile o projeto TypeScript:

```bash
npm run build
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. Copie o arquivo de exemplo de variÃ¡veis de ambiente:

```bash
cp .env.example .env
```

### 2. Escolha seu provedor LLM

O sistema suporta dois provedores de LLM:

#### ğŸŸ¢ Usando OpenAI (GPT-5)

Edite o arquivo `.env`:

```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sua_chave_api_openai_aqui
OPENAI_MODEL=gpt-5
GITHUB_TOKEN=seu_token_github (opcional)
```

**Como obter a API Key da OpenAI:**

1. Acesse [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. FaÃ§a login ou crie uma conta
3. Clique em "Create new secret key"
4. Copie a chave e adicione no `.env`

---

#### ğŸŸ£ Usando Anthropic (Claude)

Edite o arquivo `.env`:

```env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sua_chave_api_anthropic_aqui
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
GITHUB_TOKEN=seu_token_github (opcional)
```

**Como obter a API Key da Anthropic:**

1. Acesse [console.anthropic.com](https://console.anthropic.com/)
2. FaÃ§a login ou crie uma conta
3. VÃ¡ em "API Keys"
4. Clique em "Create Key"
5. Copie a chave e adicione no `.env`

---

### 3. (Opcional) Configure o GitHub Token

Para analisar repositÃ³rios privados, adicione um token do GitHub:

```env
GITHUB_TOKEN=ghp_seu_token_aqui
```

**Como obter o GitHub Token:**

1. Acesse [github.com/settings/tokens](https://github.com/settings/tokens)
2. Clique em "Generate new token (classic)"
3. DÃª um nome descritivo
4. Selecione o scope `repo` (acesso total a repositÃ³rios)
5. Clique em "Generate token"
6. Copie o token e adicione no `.env`

---

## ğŸ® Como Usar

### Executar AnÃ¡lise RepositÃ³rio Remoto

```bash
npm start repo <usuario> <repositorio>
Exemplo: npm start repo facebook react
```

### Executar AnÃ¡lise RepositÃ³rio Local

```bash
npm start local <caminho>
Exemplo: npm start local ./meu-projeto
Exemplo: npm start local data/repositories/javascript-algorithms
```

### Executar AnÃ¡lise RepositÃ³rios MÃºltiplos

```bash
npm start multiple <linguagem> [minStars] [maxRepos]
Exemplo: npm start multiple JavaScript 100 3
```

### RelatÃ³rios Gerados

ApÃ³s cada anÃ¡lise, o sistema gera dois arquivos na pasta `data/reports/`:

- **JSON**: RelatÃ³rio completo com mÃ©tricas, gaps identificados, priorizaÃ§Ãµes e sugestÃµes
- **TXT**: Logs completos da execuÃ§Ã£o para auditoria e debug

Os arquivos sÃ£o nomeados com o padrÃ£o: `<repositorio>_<modelo-llm>_<timestamp>.<extensÃ£o>`

**Exemplo de saÃ­da:**

```
ğŸ“Š RESULTADOS: react
â±ï¸  Tempo total de execuÃ§Ã£o: 245.30s
ğŸ“Š TEMPOS DETALHADOS:
   ğŸ“¦ Clonagem: 15.20s
   ğŸ“¥ InstalaÃ§Ã£o de dependÃªncias: 120.50s
   ğŸ§ª Testes: 85.30s
   ğŸ“ ExtraÃ§Ã£o de cÃ³digo: 10.20s
   ğŸ¤– AnÃ¡lise LLM: 14.10s
ğŸ“ˆ Branch coverage inicial: 78.50%
ğŸ“ˆ Line coverage inicial: 82.30%
ğŸ“„ Total de arquivos: 245
âš ï¸  Arquivos com < 90% branch coverage: 45
ğŸ“ Gaps identificados: 23
âš ï¸  Gaps priorizados: 8
ğŸ’¡ SugestÃµes: 12
```

## ğŸ“ Estrutura do Projeto

```
llm-test-coverage-analyzer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/              # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ index.ts         # ValidaÃ§Ã£o e exportaÃ§Ã£o de configs
â”‚   â”œâ”€â”€ services/            # ServiÃ§os principais
â”‚   â”‚   â”œâ”€â”€ AnalysisOrchestrator.ts  # Orquestrador de anÃ¡lises
â”‚   â”‚   â”œâ”€â”€ CoverageService.ts       # ServiÃ§o de cobertura
â”‚   â”‚   â”œâ”€â”€ GitHubService.ts         # IntegraÃ§Ã£o GitHub
â”‚   â”‚   â””â”€â”€ LLMService.ts            # IntegraÃ§Ã£o LLM (OpenAI/Anthropic)
â”‚   â”œâ”€â”€ prompts/             # Prompts para modelos LLM
â”‚   â”‚   â”œâ”€â”€ systemPrompt.ts  # Prompt do sistema (instruÃ§Ãµes)
â”‚   â”‚   â””â”€â”€ analysisPrompt.ts # Builder do prompt de anÃ¡lise
â”‚   â”œâ”€â”€ types/               # DefiniÃ§Ãµes de tipos TypeScript
â”‚   â”‚   â””â”€â”€ index.ts         # Tipos e interfaces
â”‚   â”œâ”€â”€ utils/               # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ fileSystem.ts    # OperaÃ§Ãµes de sistema de arquivos
â”‚   â”‚   â”œâ”€â”€ logger.ts        # Sistema de logs estruturados
â”‚   â”‚   â””â”€â”€ logCollector.ts  # Coletor de logs para persistÃªncia
â”‚   â””â”€â”€ index.ts             # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ dist/                    # Arquivos compilados (gerado)
â”œâ”€â”€ data/                    # Dados temporÃ¡rios e relatÃ³rios
â”‚   â”œâ”€â”€ repositories/        # RepositÃ³rios clonados
â”‚   â””â”€â”€ reports/             # RelatÃ³rios gerados (JSON e TXT com logs)
â”œâ”€â”€ package.json             # DependÃªncias do projeto
â”œâ”€â”€ tsconfig.json            # ConfiguraÃ§Ã£o TypeScript
â””â”€â”€ README.md                # Este arquivo
```

---

## ğŸ—ï¸ Arquitetura

O sistema Ã© organizado em camadas:

1. **Camada de ServiÃ§os**: ContÃ©m a lÃ³gica de negÃ³cio principal

   - `AnalysisOrchestrator`: Coordena o fluxo de anÃ¡lise
   - `CoverageService`: Processa relatÃ³rios de cobertura
   - `GitHubService`: Gerencia interaÃ§Ãµes com GitHub
   - `LLMService`: Interface unificada com modelos de linguagem (OpenAI e Anthropic)

2. **Camada de Prompts**: Prompts estruturados para comunicaÃ§Ã£o com LLMs

   - `systemPrompt`: Define o papel e instruÃ§Ãµes do modelo
   - `analysisPrompt`: ConstrÃ³i prompts dinÃ¢micos com dados de cobertura

3. **Camada de UtilitÃ¡rios**: FunÃ§Ãµes auxiliares e helpers

   - Sistema de arquivos
   - Logging estruturado com coleta automÃ¡tica
   - PersistÃªncia de logs em arquivos TXT

4. **Camada de Tipos**: DefiniÃ§Ãµes TypeScript para type-safety

5. **Camada de ConfiguraÃ§Ã£o**: Gerenciamento de variÃ¡veis de ambiente e providers LLM

### ğŸ”„ PadrÃ£o Multi-Provider

O `LLMService` implementa um padrÃ£o de estratÃ©gia que permite alternar entre diferentes provedores LLM sem modificar o cÃ³digo. O provider Ã© selecionado atravÃ©s da variÃ¡vel de ambiente `LLM_PROVIDER`.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¨â€ğŸ“ Autor

**Alison Luiz da Silva**  
RA: 220332812  
UNICESUMAR - CENTRO UNIVERSITÃRIO DE MARINGÃ

Trabalho de ConclusÃ£o de Curso - 2025

---

<div align="center">

Desenvolvido com ğŸ’™ por [Alison Luiz da Silva](https://github.com/alison-luiz)

</div>
